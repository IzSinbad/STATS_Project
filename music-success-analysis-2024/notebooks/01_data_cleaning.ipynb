{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing\n",
    "\n",
    "This notebook focuses on loading, cleaning, and preprocessing the Spotify streaming and listener preferences datasets for further analysis.\n",
    "\n",
    "## Objectives\n",
    "- Load the raw datasets\n",
    "- Explore the data structure and identify issues\n",
    "- Clean and preprocess the data\n",
    "- Save the cleaned datasets for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the src directory to the path to import custom modules\n",
    "sys.path.append('..')\n",
    "from src import data_loader\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Raw Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spotify streaming data\n",
    "spotify_df = data_loader.load_spotify_data()\n",
    "\n",
    "# Load listener preferences data\n",
    "listener_df = data_loader.load_listener_preferences()\n",
    "\n",
    "print(f\"Spotify dataset shape: {spotify_df.shape}\")\n",
    "print(f\"Listener preferences dataset shape: {listener_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore the Spotify Streaming Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows\n",
    "spotify_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names and data types\n",
    "spotify_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "spotify_missing = spotify_df.isnull().sum()\n",
    "print(\"Columns with missing values:\")\n",
    "print(spotify_missing[spotify_missing > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "print(f\"Number of duplicate rows: {spotify_df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics for numeric columns\n",
    "spotify_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore the Listener Preferences Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows\n",
    "listener_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names and data types\n",
    "listener_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "listener_missing = listener_df.isnull().sum()\n",
    "print(\"Columns with missing values:\")\n",
    "print(listener_missing[listener_missing > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "print(f\"Number of duplicate rows: {listener_df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics for numeric columns\n",
    "listener_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clean the Spotify Streaming Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy to avoid modifying the original\n",
    "spotify_clean = spotify_df.copy()\n",
    "\n",
    "# Remove duplicate rows if any\n",
    "spotify_clean = spotify_clean.drop_duplicates()\n",
    "\n",
    "# Check for string columns that should be numeric\n",
    "# For example, some numeric columns might have quotes or commas\n",
    "numeric_cols = spotify_clean.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    # Check if the column contains numeric values with quotes\n",
    "    if spotify_clean[col].str.contains('\"').any():\n",
    "        # Remove quotes and convert to numeric\n",
    "        spotify_clean[col] = spotify_clean[col].str.replace('\"', '')\n",
    "        \n",
    "    # Check if the column contains numeric values with commas\n",
    "    if spotify_clean[col].str.contains(',').any():\n",
    "        # Remove commas and convert to numeric\n",
    "        spotify_clean[col] = spotify_clean[col].str.replace(',', '')\n",
    "    \n",
    "    # Try to convert to numeric\n",
    "    try:\n",
    "        spotify_clean[col] = pd.to_numeric(spotify_clean[col])\n",
    "        print(f\"Converted {col} to numeric\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "spotify_clean = data_loader.clean_spotify_data(spotify_clean)\n",
    "\n",
    "# Check if all missing values have been handled\n",
    "print(\"Columns with missing values after cleaning:\")\n",
    "print(spotify_clean.isnull().sum()[spotify_clean.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types after cleaning\n",
    "spotify_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Clean the Listener Preferences Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy to avoid modifying the original\n",
    "listener_clean = listener_df.copy()\n",
    "\n",
    "# Remove duplicate rows if any\n",
    "listener_clean = listener_clean.drop_duplicates()\n",
    "\n",
    "# Handle missing values\n",
    "listener_clean = data_loader.clean_listener_preferences(listener_clean)\n",
    "\n",
    "# Check if all missing values have been handled\n",
    "print(\"Columns with missing values after cleaning:\")\n",
    "print(listener_clean.isnull().sum()[listener_clean.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types after cleaning\n",
    "listener_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Additional Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create age groups in the listener dataset\n",
    "if 'Age' in listener_clean.columns:\n",
    "    bins = [0, 18, 25, 35, 45, 55, 65, 100]\n",
    "    labels = ['<18', '18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "    listener_clean['Age Group'] = pd.cut(listener_clean['Age'], bins=bins, labels=labels)\n",
    "    \n",
    "    # Check the distribution of age groups\n",
    "    print(\"Age group distribution:\")\n",
    "    print(listener_clean['Age Group'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a release year column in the Spotify dataset if it has a release date\n",
    "if 'Release Date' in spotify_clean.columns:\n",
    "    # Check if Release Date is already a datetime\n",
    "    if pd.api.types.is_datetime64_any_dtype(spotify_clean['Release Date']):\n",
    "        spotify_clean['Release Year'] = spotify_clean['Release Date'].dt.year\n",
    "    else:\n",
    "        # Try to convert to datetime\n",
    "        try:\n",
    "            spotify_clean['Release Date'] = pd.to_datetime(spotify_clean['Release Date'])\n",
    "            spotify_clean['Release Year'] = spotify_clean['Release Date'].dt.year\n",
    "        except:\n",
    "            print(\"Could not convert Release Date to datetime\")\n",
    "    \n",
    "    # Check the distribution of release years\n",
    "    if 'Release Year' in spotify_clean.columns:\n",
    "        print(\"Release year distribution:\")\n",
    "        print(spotify_clean['Release Year'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save the Cleaned Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a processed data directory if it doesn't exist\n",
    "processed_dir = os.path.join('..', 'data', 'processed')\n",
    "if not os.path.exists(processed_dir):\n",
    "    os.makedirs(processed_dir)\n",
    "\n",
    "# Save the cleaned Spotify dataset\n",
    "spotify_clean_path = os.path.join(processed_dir, 'spotify_clean.csv')\n",
    "spotify_clean.to_csv(spotify_clean_path, index=False)\n",
    "print(f\"Saved cleaned Spotify dataset to {spotify_clean_path}\")\n",
    "\n",
    "# Save the cleaned listener preferences dataset\n",
    "listener_clean_path = os.path.join(processed_dir, 'listener_clean.csv')\n",
    "listener_clean.to_csv(listener_clean_path, index=False)\n",
    "print(f\"Saved cleaned listener preferences dataset to {listener_clean_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Data Cleaning\n",
    "\n",
    "In this notebook, we have:\n",
    "1. Loaded the raw Spotify streaming and listener preferences datasets\n",
    "2. Explored the data structure and identified issues\n",
    "3. Cleaned and preprocessed the data, including:\n",
    "   - Handling missing values\n",
    "   - Converting data types\n",
    "   - Removing duplicates\n",
    "   - Creating derived features (age groups, release years)\n",
    "4. Saved the cleaned datasets for further analysis\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "The cleaned datasets are now ready for exploratory analysis in the next notebook:\n",
    "- `02_exploratory_analysis.ipynb`: Descriptive statistics and simple visualizations\n",
    "\n",
    "This will help us understand the distributions, patterns, and relationships in the data before proceeding to more advanced statistical analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
